# Week 2

## 1. When can machine learn?

### Hypothesis: 'perceptron'

Each "tall" **w** represents a hypothesis _h_ & multiply the "tall" **x**.

Perceptron is equivalent to linear (binary) classifier.

### Perceptron Learning Algorithm

want g is close to f (hard when _f_ unknow)

Ideally, g(xn) = f(xn) = yn

Difficulty: H is infinite space.

Idea: start from some g0, and correct its mistakes on D.

Algorithm:
1. Find a mistakes xn(t)
2. Updates w(t+1) <- w(t) + yn(t)\*xn(t)
Geometric explaination: if the angle between w and x is too big, we make it
smaller, otherwise, make it bigger.

A fault confessed is half redressed.

## Guarantee of PLA

The normalized inner product of w_f and w_t will increase monotonously.
It will stop at certain iteration.

## Non separable data

Pros: simple to implement, fast, work for any dimension d.
Cons:
* Assume linearly separable.
* not fully sure how long halting takes (rho depends on wf)

PLA Algorithm

Run enough iteration.

# Types of Learning

## Learning with different output space

Binary classification
* Credit card approval
* Email spam/not spam
* Patient sick/not sick
* ad profitable/not profitable
* answer correct/incorrect

## Learning with different labels
## Learning with different protocols
## Learning with different input space

# Feasible of Learning

## Learning is impossible?

## Probability to the Rescue

Bin model.

in sample nu is likely close to unknow mu

Hoeffding's Inequality:

probably approximately correct (PAC).

## Connection to Learning

Learning.

Unknown **f**
target f(x)

h is wrong/orange equivalent h(x) not equals to f(x)
h is right/green
Check h on D = {(xn, yn)}

### Added components

Ein: in sample
Eout: out sample

### The Formal Guarantee

* Valid for all N and epsilon.
* Doesn't depend on Eout(h), f and P can stay unknown.
* Ein(h) = Eout(h) is PAC.

## Connection to real learning

### BAD Data for Many h

no 'freedom of choice' by A, 踩到雷。

### Bound of BAD data

|H| = M is finite, N large enough, for whatever g picked by A, Eout(g) = Ein(g)
if A finds one g with Ein(g) = 0, PAC guarantee for Eout(g) = 0.
